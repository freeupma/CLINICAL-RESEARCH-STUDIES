# -*- coding: utf-8 -*-
"""CLINICAL TRIAL STUDIES

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Y-sHmffIr9a2vW0OoIj59HDuL8cjICcX

#**A Machine Learning Model to Predict Whether a Clinical Trial Study Will Be Completed or Terminated**

##**1. Statement of the Problem**


In the field of clinical research, the timely and efficient completion of clinical trials is of paramount importance for the development of new treatments and therapies. However, the factors influencing the termination or successful completion of different clinical trial phases are complex and multifaceted. Currently, there exists a need for a reliable predictive model leveraging Machine Learning techniques to anticipate the outcomes of clinical trials. Given a comprehensive dataset encompassing crucial parameters such as NCT number, study title, study status, conditions, interventions, phases, enrollment, study type, study design, start date, completion dates, and various other relevant attributes, the challenge is to develop an accurate and robust machine learning model. This model should predict with precision whether a clinical trial will be terminated prematurely or completed successfully based on the provided dataset. The predictive analysis is expected to consider diverse variables including study demographics, trial specifics, and organizational aspects (such as sponsors and collaborators) to provide actionable insights. This model will aid researchers, sponsors, and regulatory bodies in optimizing resource allocation, improving decision-making, and ensuring the successful progression of clinical trials.

###1.1 Objectives

#a) Main objectives

*   To perform an extensive Explaratory Data Analysis to uncover hidden trends and patterns.

*   To develop a machine learning model for clinical studies to help predict the completion or termination of clinical trials.




#b) Specific objectives

* To establish the type of clinical studies conducted.
* To obtain the number of clinical trial studies in each phase(Phase1 to Phase 3).
* To find the most studied diseases
* To find out the top sponsors of the clinical studies.


*   To find out the statuses of the registered clinical studies
*   To establish the most commonly used method of clinical studies

### 1.2 Defining the Metric for Success

*   Perform Exploratory Data Analysis on the dataset.

*   Project will be considered successful if we achieve an F1 score of 1.

###1.3 Understanding the Variables

The dataset contains records under 30 atrributes.

1. **NCT Number:** The unique identifier assigned to a clinical trial when registered on ClinicalTrials.gov.
2. **Study Title:** The formal title of the clinical trial, describing the research, the population studied, and the purpose of the study.

3. **Study URL:** The web address where detailed information about the clinical trial can be accessed online.

4. **Acronym:** An abbreviation formed from the initial letters of each word in the study title.

5. **Study Status:** Indicates the current status of the clinical trial, such as recruiting, active, completed, terminated, or withdrawn.

6. **Brief Summary:** A concise description of the clinical trial's purpose, methods, and goals.

7. **Study Results:** Specifies whether the trial has reported its results and, if so, provides a summary of the outcomes.

8. **Conditions:** Describes the medical conditions or diseases the clinical trial aims to address or study.

9. **Interventions:** Details the treatments, drugs, procedures, or other interventions being tested in the trial.

10. **Primary Outcome Measures:** Specifies the main objectives of the study, such as specific measurements or observations used to evaluate the trial's primary effectiveness or success.

11. **Secondary Outcome Measures:** Additional measurements or observations, beyond the primary outcome, used to assess other aspects of the intervention's impact or safety.

12. **Sponsors:** The individual, organization, company, or institution responsible for initiating, managing, and financing the clinical trial.

13. **Collaborators:** Other entities, such as institutions or research groups, involved in the clinical trial alongside the primary sponsor.

14. **Sex:** Indicates the gender of the participants involved in the trial.

15. **Age:** Specifies the age range or demographic characteristics of the participants eligible for the clinical trial.

16. **Phases:** Indicates the stage of the clinical trial (Phase 0, Phase 1, Phase 2, Phase 3, or Phase 4) and its purpose (testing safety, efficacy, or comparing to standard treatments).

17. **Enrollment:** The number of participants planned or enrolled in the clinical trial.

18. **Funder Type:** Describes the type of funding source for the trial, such as government, industry, academic, or non-profit organizations.

19. **Study Type:** Specifies the type of clinical trial, such as interventional (testing treatments) or observational (observing participants without intervention).

20. **Study Design:** The overall plan for the clinical trial, including its structure, duration, and methodology.

21. **Start Date:** The date when the clinical trial officially began.

22. **Primary Completion Date:** The anticipated date when the final participant's data for the primary outcome measure is collected.

23. **Completion Date:** The anticipated or actual date when the clinical trial concludes, including data analysis and reporting.

24. **Locations:** The geographical locations (hospitals, clinics, countries, etc.) where the clinical trial is conducted.

25. **Study Documents:** Any additional documents or files related to the clinical trial, which might include protocols, informed consent forms, or publications.

26. **Other Outcome Measures:** Includes any secondary or additional measurements, assessments, or observations made during the clinical trial that are not specified as primary or secondary outcome measures.

27.  **Other IDS:** Contain additional identification numbers or codes related to the clinical trial, which could be used for tracking purposes in databases or systems

28.  **First Posted:** The date when the clinical trial was first publicly registered or posted on a clinical trials registry.

29.  **Results First Posted:** The first time when the results or outcome data of the clinical trial were made publicly available.

30.  **Last Update Posted:** This is the most recent date when any updates or changes to the clinical trial information, including changes in the protocol, participant eligibility criteria, or outcome measures, were made publicly available.

### 1.4 Recording the Experimental Design

Perform the following operations:

* Define the research question
* Load data and preview the dataset
* Data cleaning
* Perform univariate, bivariate analysis
* Implement the solution
* Challenge the solution

### 1.5 Data Relevance


The dataset is relevant for this analysis. It summarizes the outcomes of 161,863 clinical trial studies. The datasets provide a complete overview of the information required to develop a ML model to predict the termination or completion of clinical trials.

The dataset was extracted from [ClinicalTrials.gov](https://clinicaltrials.gov/).

##**2. Load the Dataset**
"""

# Commented out IPython magic to ensure Python compatibility.
#Import the required libraries

import pandas as pd
import numpy as np
from matplotlib import pyplot as plt
# %matplotlib inline
import matplotlib
import seaborn as sns
from plotly.subplots import make_subplots
import plotly.graph_objects as go
import glob



import warnings

# Filter out specific warnings (e.g., FutureWarnings)
warnings.filterwarnings('ignore', category=FutureWarning)

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
# Path to the directory containing your CSV files
csv_directory = '/content/drive/MyDrive/DTE'

# List all CSV files in the directory

# The global module searches for files that match a specific file pattern/name

# It can be used to search CSV files and for text in files.
csv_files = glob.glob(f'{csv_directory}/*.csv')

# Initialize an empty list to store individual dataframes
dfs = []

# Read each CSV file and append it to the list
for csv_file in csv_files:
    df = pd.read_csv(csv_file)
    dfs.append(df)

# Concatenate all dataframes into one
# If True, do not use the index values along the concatenation axis
# The resulting axis will be labeled 0, â€¦, n - 1
combined_df = pd.concat(dfs, ignore_index=True)

# Save the combined dataframe to a new CSV file
combined_df.to_csv('combined_file.csv', index=False)

print('CSV files combined successfully and saved as combined_file.csv')

# Replace spaces with underscores in column names

combined_df.columns = combined_df.columns.str.replace(' ', '_')
combined_df.head(5)

"""**Observation**

* Replaced the white spaces with underscores on the column.
"""

#A list of all columns
combined_df.columns

"""##**3. Exploratory Data Analysis**

> EDA is used to investigate the dataset and summarize the key insights. It gives the basic understanding of the data, it's distribution, and relationship between variables. Graphs and python functions are used to explore the data. There will be two type of analysis; univariate and bivariate analysis. We will perform the following:

**2.1) Understanding Your Variables**


> 2.1.1) Head of the dataset

> 2.1.2) The shape of the dataset

> 2.1.3) List the types of the columns

> 2.1.4) Summary of the dataset


**2.2) Data Cleaning**

>2.2.1) Check for duplicates

>2.2.2) Check for NULL values

**2.1.1) Head of the dataset**
"""

# Display the top 5 rows
combined_df.head()

"""**2.1.2) Shape of the dataset**"""

combined_df.shape

"""**Observation**

* The dataset contains 30 columns and 161,863 rows

**2.1.3) List of the data types of the columns**
"""

combined_df.dtypes

"""**Observation**

* 29 columns are objects(strings) while the Enrollment column is in float format
* We need to put the dates in the correct data type(datetime) and Enrollement into integer form.

**2.1.4) Statistical Summary of the dataset**
"""

#Statistical summary of the numerical column(Enrollment)
combined_df.describe()

"""**Observation**

* The row count is 158,390, which indicates the presence of missing values since the row are 161,863.
* The mean and standard deviation are 9.37400e+03 & 7.689174e+05 respectively.
* The IQR values(25%, 50%, and 75%) are 3.000000e+01, 7.600000e+01,and 2.340000e+02.

**2.2) Data Cleaning**

**2.2.1) Check for duplicates**
"""

# Check if there are duplicate rows or not; remove if present
# Check the shape before we drop the duplicates

combined_df.shape

"""**Observation**

* The initial rows are 161,863 and columns are 30
"""

#Drop duplicate rows

combined_df=combined_df.drop_duplicates()

#Check the shape after dropping the duplicate rows
combined_df.shape

"""**Observation**

* 9,705 duplicate rows have been dropped.
* The dataset now has 152,158 rows and 30 columns

**2.2.2) Check for null values**
"""

#get the total number of null values in each column

combined_df.isnull().sum()

object_cols=['Acronym','Interventions',
       'Primary_Outcome_Measures', 'Secondary_Outcome_Measures',
       'Other_Outcome_Measures', 'Collaborators', 'Sex',
       'Phases', 'Enrollment', 'Study_Design',
       'Other_IDs', 'Start_Date', 'Primary_Completion_Date', 'Completion_Date', 'Results_First_Posted'
       'Locations', 'Study_Documents']

"""**Observation**

* There are a lot of missing values in the columns highlighted above. Each column's null values will be handled differently. For the 'Enrollment' column,we will fill the null values with the mean.
"""

#For the ENROLLEMENT column Impute mean

mean = combined_df['Enrollment'].mean()


# Impute missing values with the mean
combined_df['Enrollment'].fillna(mean, inplace=True)

#ensure the change has been effected
combined_df['Enrollment'].isnull().sum()

"""**Observation**

* There are no missing values in the Enrollment column(imputed mean)
* We proceed to change the data type into integer format
"""

#change the Enrollement column into the correct datatype

combined_df['Enrollment'] = combined_df['Enrollment'].round().astype(int)
combined_df['Enrollment'].head(3)

"""**Observation**

* The Enrollement data type has been changed into integer since we are dealing with human subjects.
"""

# Change the dates into datetime format

#create a dictionary to store the date variables

date_columns=['Start_Date','Primary_Completion_Date','Completion_Date',
              'First_Posted','Results_First_Posted','Last_Update_Posted']

#to avoid repetition,use a for loop function to change the datatypes to datetime
for col in date_columns:
  combined_df[col] = pd.to_datetime(combined_df[col])

combined_df.dtypes

"""**Observation**

* The dates have been converted to the datetime module, which provides classes for working with dates and time from the initial object data type.
"""

# Replace all the missing values with 'Missing' for columns in object datatype

#create a dictionary to store these columns

object_cols=['Acronym','Interventions',
       'Primary_Outcome_Measures', 'Secondary_Outcome_Measures',
       'Other_Outcome_Measures', 'Collaborators', 'Sex',
       'Phases', 'Study_Design','Other_IDs','Locations', 'Study_Documents']
for col in object_cols:
    combined_df[col].fillna('Missing', inplace=True)

#Replace missing values with 'Missing' for 'Conditions' column
combined_df.Conditions.fillna('Missing',inplace=True)

#confirm
combined_df.isnull().sum()

"""**Observation**

* The are no null values in the categorical columns except for the date columns denoted by NAT

### 3.1 Univariate Analysis

 It will involve the analysis of a single variable to understand its distribution, central tendency, spread, and other important properties using  popular libraries like Matplotlib, Seaborn, and Pandas
"""

# Horizontal bar of our target variable
import matplotlib.pyplot as plt

combined_df['Study_Results'].value_counts().plot(kind='bar', color='Blue')
plt.xlabel('Count', fontsize= 10)
plt.ylabel('Study_Results', fontsize= 10)
plt.xticks(rotation = 45)
plt.title('Do we have any results to study?', fontsize = 15);

"""**Observation**

* Only a small number of the clinical trials have the final study results.
"""

#find unique values and their counts
unique_values = combined_df['Study_Results'].value_counts()

# Print unique values and their counts
for value, count in unique_values.items():
    print(f'Value: {value}, Count: {count}')

"""**Observation**

* The number of the clinical trials with study results are 19,232 while those without results  are 132,926.
"""

# Target completion dates for the studies

combined_df['Completion_Date'].dt.year.hist( bins=10, color='skyblue', edgecolor='black')

"""**Observation**

* The studies were completed between 2000 and 2040.
"""

#Pie chart showing the types of studies

import seaborn as sns
import matplotlib.pyplot as plt

# The data
labels = ['INTERVENTIONAL', 'OBSERVATIONAL', 'EXPANDED_ACCESS']
sizes = [120468, 40896, 499]

# Creating a pie chart using Seaborn
plt.figure(figsize=(8, 6))

sns.set_palette("pastel")  # Set color palette

Explode=[0.1,0,0] # Emphasize on a particular part

plt.pie(sizes, labels=labels, explode=Explode, autopct='%1.1f%%', startangle=140, shadow=True)

plt.title('A Pie Chart Showing the Types of Studies Conducted')
plt.show()

"""**Observation**

 * 25.3% of the studies conducted were observational; in this; case the researchers observed the effect of a risk factor, diagnostic test, treatment or other intervention without trying to change who was or isn't exposed to it.


*   74.4% of the studies were interventional; the research where potential drugs or procedures were done on the subjects.  

*   Expanded access contributes 0.3% of the studies; where the subjects with life-threatening conditions were given access to the investigational product outside the clinical trials




"""

#find unique values in the various clinical trial phases and their counts

unique_valu = combined_df['Phases'].value_counts()
unique_valu

# A histogram showing the distribution of subjects in the various trial phases
import matplotlib.pyplot as plt

value_counts = combined_df['Phases'].value_counts()
sorted_value_counts = value_counts.sort_values(ascending=True)  # Sort in ascending order

# Create a horizontal bar plot
plt.barh(sorted_value_counts.index, sorted_value_counts.values, color='skyblue')

# Annotate each bar with values (outside the bar)
for index, value in enumerate(sorted_value_counts.values):
    plt.text(value, index, str(value), ha='left', va='center')  # Place labels outside the bar on the right

plt.xlabel('Count')
plt.ylabel('Clinical Trial Phases')
plt.title('Clinical Trial Phases')
plt.xticks(rotation='horizontal')
plt.show()

"""* Most trials(29,855) are in the Phase 2 where the researchers aim to find out if the new treatment works well enough to be tested in a larger phase 3 trial
* 16,964 trial studies are in Phase 1 where the aim is to determine the optimal dosage and method of administration.
* 2,138 studies are in Phase 2|Phase 3, which provides a bridge between the initial efficacy and safety testing.
* 12,195 studies are in Phase 3, a stage that is pivotal in determining  whether a new drug or treatment will be made available to the public.
* Only 1,780 studies are in Phase 1 where the primary objective is to assess the safety and dosage tolerance of the intervention.
* The number of studies with missing information on clinical phases are 74,162.

"""

data = combined_df['Study_Status'].value_counts(normalize=True).sort_values(ascending=True)

# Define the font size for labels
label_fontsize = 12

# Create a horizontal bar plot using Matplotlib
plt.figure(figsize=(10, 6))
bars = plt.barh(data.index, data.values, color='blue')

# Annotate each bar with percentages (outside the bar) with custom font size
for bar in bars:
    width = bar.get_width()
    plt.text(width, bar.get_y() + bar.get_height() / 2, f'{width:.2%}', ha='left', va='center', color='black', fontsize=label_fontsize)

plt.xlabel('Frequency', fontsize=label_fontsize)
plt.title('Clinical Trial Study Status', fontsize=label_fontsize)
plt.xticks(rotation='horizontal', fontsize=label_fontsize)

# Edit the font size of y-axis labels
plt.yticks(fontsize=label_fontsize)

plt.show()

"""**Observation**

* 46.57% of the trials were completed according to the protocol.
* 16.94% of the clinical trials are actively recruiting participants who meet the study criteria.
* Another 13.75% of the clinical trials have their status as unknown and this can happen for various reasons, such as data reporting delays or lack of available information.
* 7.62% of the clinical trial studies were terminated before its planned completion, and this can happen due to safety concerns, lack of efficacy, or other reasons.
* 6.16% of the trials are active but not recruiting; the trials are ongoing, but new participants are not being recruited or enrolled. Current participants continue to be monitored and treated.
* 4.44% of the studies are yet to recruit participants.
* 3.18% of the clinicals were withdrawn from the study; the trials have been stopped before planned enrollment begun.

"""

# A bar plot displaying the various sponsors of the clinical trial studies
top_10_sponsors = combined_df['Sponsor'].value_counts().head(10).sort_values(ascending=True)

# Create a horizontal bar chart for the top 10 sponsors
plt.figure(figsize=(12, 6))
top_10_sponsors.plot(kind='barh', color='skyblue')
plt.xlabel('Count')
plt.ylabel('Sponsor')
plt.title('Top 10 Sponsors For The Clinical Trial Studies')
plt.xticks(rotation='horizontal')
plt.show()

"""**Observation**

* The top 5 sponsors of these clinical trial studies are based in the United States of America: they are government agencies and hospita/healthcare systems.
* The pharmaceutical companies(Novartis-Switzerland, Astrazeneca-U.K, Hoffman-La-Roche-Switzerland, and Pfizer-U.S.A) come in closely.

"""

Bottom_5_sponsors = combined_df['Sponsor'].value_counts().tail(5)

# Create a horizontal bar chart for the top 10 sponsors
plt.figure(figsize=(10, 6))
Bottom_5_sponsors.plot(kind='barh', color='skyblue')
plt.xlabel('Count')
plt.ylabel('Sponsor')
plt.title('Bottom 5 Sponsors of Clinical Trials')
plt.xticks(rotation='horizontal')
plt.show()

"""**Observation**

* Some university hospitals, private research universities, medical doctors, and biopharmaceuticals comprise the last 5 sponsors in the clinical trial studies.
"""

# Top most studied conditions
import pandas as pd
import plotly.express as px

# Group by 'Conditions' and count the occurrences, then sort and select the top 10
top10 = combined_df['Conditions'].value_counts().nlargest(10)

# Create a DataFrame with 'Conditions' and 'Total Trials' columns
top10_df = pd.DataFrame({'Conditions': top10.index, 'Total Trials': top10.values})

# Create the bar chart
fig = px.bar(top10_df,
             title='<b>The 10 Most Studied Conditions</b>',
             x='Total Trials',
             y='Conditions',
             color='Total Trials',
             color_continuous_scale=px.colors.qualitative.Pastel,
             orientation='h',
             height=500,
             width=800)

fig.update_layout(title_x=0.5, title_y=0.9, font=dict(size=14))
fig.update_layout(showlegend=False)

fig.show()

"""**Observation**

* Six of the top 10 conditions in trial are on cancer. The studied cancer types are that of the breast, prostate, colorectal, lungs, and bones.
* The other 4 diseases are HIV, Covid-19, Heart Failure, and Coronary Artery Disease.
"""

# Age of the study participants

# Set a custom color palette for the plot
custom_palette = sns.color_palette("Blues", n_colors=len(combined_df['Age'].unique()))

plt.figure(figsize=(8, 6))
ax = sns.barplot(x=combined_df['Age'].value_counts().values,
                y=combined_df['Age'].value_counts().index,
                palette=custom_palette)

plt.xlabel('Frequency', fontsize=14)
plt.ylabel('Age', fontsize=5)
plt.title('Age of The Participants', fontsize=16)
plt.grid(axis='y', linestyle='--', alpha=0.6)

plt.yticks(fontsize=12)
plt.xticks(fontsize=12)
plt.show()

"""**Observation**

* Most of participants are of the category "Adults and Older Adults". "Adults" are individuals between the ages of 18 and 64 years old and the "Older adults" refer to individuals who are usually 65 years old or above.
* Clinical trials include older adults to understand how treatments affect this age group, especially since the prevalence of many diseases, including cancer and chronic conditions, increases with age.
"""

location_column = 'Locations'

# Get the top 5 locations by frequency
top_locations = combined_df[location_column].value_counts().head(5).index

# Filter the dataset to include only the top 5 locations
filtered_df = combined_df[combined_df[location_column].isin(top_locations)]

# Set the font size for the plot
sns.set(font_scale=2.5)

# Create a count plot for the top 5 locations with location names on the y-axis
plt.figure(figsize=(25, 15))
sns.countplot(data=filtered_df, y=location_column, order=top_locations, palette='viridis')
plt.title(f'Distribution of Top 5 Locations in Clinical Trials')
plt.xlabel('Count')
plt.ylabel(location_column)

plt.show()

"""**Observation**
*   The data is missing Location data for most of the studies.
*   Most of the studies were conducted at the M D Anderson Cancer Center,Houston, Texas in the US.

### 3.2 Bivariate Analysis###

 It will involve the simultaneous analysis of two variables ( independent and dependent variables) to determine the empirical relationship between them.
"""

# A comparison of the study study by the type of study

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(12, 6))
sns.countplot(data=combined_df, y='Study_Status', hue='Study_Type')

plt.title('Comparison of Study Status by Study Type', fontsize=14)
plt.xlabel('Count', fontsize=12)
plt.ylabel('Study Status', fontsize=12)
plt.xticks(rotation=80, fontsize=10)
plt.yticks(fontsize=10)
plt.legend(title='Study Type', title_fontsize=10, fontsize=10,loc='lower right')
plt.show()

"""**Observations**

* Most of the clinical trial studies are interventional in nature followed by the observational ones.
* Most of the completed and currently recruiting clinical trials are interventional.
* The **completed interventional trials** confirm the effectiveness and safety of specific interventions, guiding medical practice, while **completed observational trials** offer valuable insights into real-world health patterns, influencing public health strategies and suggesting areas for future investigation.

"""

# Calculate the mean enrollment by study type
mean_enrollment_by_study_type = combined_df.groupby('Study_Type')['Enrollment'].mean().reset_index()

# Sort the data in descending order by mean enrollment
mean_enrollment_by_study_type = mean_enrollment_by_study_type.sort_values('Enrollment', ascending=False)

plt.figure(figsize=(12, 6))

# Create a barplot with a custom color palette
sns.barplot(data=mean_enrollment_by_study_type, x='Enrollment', y='Study_Type', palette='viridis')

plt.title('Comparison of Mean Enrollment by Study Type', fontsize=16)
plt.xlabel('Mean Enrollment', fontsize=14)
plt.ylabel('Study Type', fontsize=14)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)
plt.show()

"""**Observation**




*   The number of participants enrolled in the Observational studies is higher than Expanded Access and Interventional methods of study.
*   Interventional studies enrolled less particpants.





"""

combined_df.columns

# Calculate the mean enrollment by study type
mean_enrollment_by_study_status = combined_df.groupby('Study_Status')['Enrollment'].mean().reset_index()

# Sort the data in descending order by mean enrollment
mean_enrollment_by_study_status = mean_enrollment_by_study_status.sort_values('Enrollment', ascending=False)

plt.figure(figsize=(12, 6))

# Create a barplot with a custom color palette
sns.barplot(data=mean_enrollment_by_study_status, x='Enrollment', y='Study_Status', palette='viridis')

plt.title('Comparison of Mean Enrollment by Study status', fontsize=16)
plt.xlabel('Mean Enrollment', fontsize=14)
plt.ylabel('Study Status', fontsize=14)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)
plt.show()

"""**Observation**


*   Terminated and withdrawn  studies recorded the lowest number of enrollment.

##**4. Implementing The Solution**

Modeling in this phase will include selecting a machine learning technique;designing the test; building the model and assessing model that will predict whether a clinical trial will be completed or terminated.

### 4.1 Data Pre-Processing
"""

# Import the required libraries
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import MinMaxScaler
from sklearn.svm import SVC
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import numpy as np
import pandas as pd

# Select the Y variable; in this case it is the study_status

combined_df.Study_Status.value_counts()

#filter the study status to get only the completed and Terminated clinical trial studies

# STATUS is the new dataframe with COMPLETED and TERMINATED studies

import re
status= combined_df[combined_df['Study_Status'].str.contains(r'^(COMPLETED|TERMINATED)', case=False, na=False, regex=True)]

#previewing
status.head(5)

status.Study_Status.value_counts()

"""**Observation**

* The dataset above has only the studies that were completed or terminated.
"""

#checking the shape
status.shape

"""**Observation**

* The working dataset now has 82,460 rows and 30 columns
"""

#let's encode the categorical features i.e convert them to numerical values
from sklearn.preprocessing import LabelEncoder

# Function to label encode the categorical variables
def encode_categorical_features(dataframe):
    encoded_dataframe = dataframe.copy()  # Create a copy of the original DataFrame

    for column in dataframe.columns:
        if dataframe[column].dtype == 'object':
            encoder = LabelEncoder()
            encoded_dataframe[column] = encoder.fit_transform(dataframe[column])

    return encoded_dataframe

# Example usage:
encoded_status = encode_categorical_features(status)

# Print the top 5 encoded rows

encoded_status.head(5)

"""**Observation**

* The new dataframe called **encoded_status** contains numerical values. Label Encoding assigns a unique numerical value to each category in a categorical variable, essentially converting the categories into integers.
"""

# List of columns to drop
columns_to_drop = ['Study_URL', 'Acronym', 'Brief_Summary', 'Primary_Outcome_Measures','Secondary_Outcome_Measures','Other_Outcome_Measures','Other_IDs','Results_First_Posted','Study_Documents']

# Drop the specified columns
encoded_status.drop(columns=columns_to_drop, inplace=True)

#Drop the dates in datetime format

df = pd.DataFrame(encoded_status)


df.drop(columns=['Start_Date','Primary_Completion_Date','Completion_Date','First_Posted','Last_Update_Posted'], axis=1, inplace=True)

df.shape

"""**Observation**

* The dataframe named df will be used for modelling. It has 16 columns, and 82,460 rows

**Split data into X and y**
"""

target='Study_Status'

y=df[target]
X=df.drop(target,axis=1)

#Split into X_train, X_test, y_train, y_test
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 0)

#scaling using MinMax scaler which  scales features to a specified range, usually [0, 1]

# X-train(fit,transform)----- scales the data, and the result is stored in a DataFrame.
training_scaler = MinMaxScaler().fit(X_train)
training_set = training_scaler.transform(X_train)

#X_TEST(FIT,TRANSFORM)
testing_scaler = MinMaxScaler().fit(X_test)
testing_set = testing_scaler.transform(X_test)

# Check our X(independent) features

X.head(3)

"""**Observation**

* Has 15 columns except for the **Study_Status** column; our dependent variable
"""

# Check the y features
y.head(6)

"""**Observation**

Our binary target variable is the **Study_Status** column; ie y variable
"""

X_train.shape

"""**Observation**

* 65,968 independent variable equals the 80% (80/20% split) that will be used for training.
"""

X_test.shape

"""**Observation**

* The 20% that will be used for test are 16,492 independent features

###4.2 Modelling

Will be utilizing XGBoost, a powerful gradient boosting algorithm, for the modeling task.

XGBoost is known for its speed, efficiency, and effectiveness in handling both classification(in our case) and regression problems. It employs boosting techniques to create a robust ensemble of decision trees, iteratively correcting errors and enhancing accuracy. It is capable of handling large datasets while maintaining model performances.

XGBoost can handle imbalanced data, but it will require additional tuning to effectively address the class imbalance.

>
"""

#Develop  a predictive model using XGboost; an optimized gradient boosting algorithm

from sklearn.metrics import classification_report, confusion_matrix

from xgboost import XGBClassifier

model = XGBClassifier()
model.fit(X_train, y_train)

# make predictions for test data
y_pred = model.predict(X_test)
predictions = [round(value) for value in y_pred]

# evaluate predictions
accuracy = accuracy_score(y_test, predictions)
print("Accuracy: %.2f%%" % (accuracy * 100.0))
from sklearn.metrics import classification_report, confusion_matrix

print(confusion_matrix(y_test,predictions))
print(classification_report(y_test, predictions))

"""**Observation**
*   Our model correctly predicts that 13915 studies were completed and  757 studies were terminated.
*   On the other hand,it makes 317 predictions about studies being completed while in real sense they were terminated. It wrongly predicts that 1501 studies were terminated yet they were completed.


*   Going by the F1 Score, the model is 94% right about the 0 class which represents 'COMPLETED' and 45% right about class 1 which represents 'TERMINATED'.
*   It gives us an overall accuracy of 89%.

**Tune the XGboost model**
"""

import xgboost as xgb
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

# Our features in X and labels in y
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Use XGBoost DMatrix, an interface that is optimized for both memory efficiency and training speed.
dtrain = xgb.DMatrix(X_train, label=y_train)
dtest = xgb.DMatrix(X_test, label=y_test)

# Set hyperparameters
params = {
    'objective': 'binary:logistic',  # for our binary classification problem
    'max_depth': 3, #  limits the maximum depth of each decision tree in the ensemble
    'learning_rate': 0.1, #  the model's weights are updated by 10% of their current value during each iteration
    'eval_metric': 'logloss' # quantifies the accuracy of a classifier by penalizing false classifications
}
# Train the model
num_rounds = 100  # Number of boosting rounds (iterations)
xgb_model = xgb.train(params, dtrain, num_rounds, evals=[(dtest, 'eval')])

# Make predictions on the test data
y_pred = xgb_model.predict(dtest)

# Convert probabilities to binary predictions (0 or 1)
predictions = [1 if pred > 0.5 else 0 for pred in y_pred]

# Evaluate the model
accuracy = accuracy_score(y_test, predictions)
print("Accuracy: %.2f%%" % (accuracy * 100.0))
from sklearn.metrics import classification_report, confusion_matrix

print(confusion_matrix(y_test,predictions))
print(classification_report(y_test, predictions))

"""## **5. Challenging the Solution**"""

# Use a different ML technique and compare with XGboost; in this case we use Random Forest


from imblearn.over_sampling import RandomOverSampler
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score
from sklearn.metrics import classification_report, confusion_matrix


# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Perform oversampling on the training data using RandomOverSampler
oversampler = RandomOverSampler(random_state=42)
X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)

# Create a Random Forest classifier
rf_classifier = RandomForestClassifier(random_state=42)

# Train the Random Forest classifier on the oversampled data
rf_classifier.fit(X_train_resampled, y_train_resampled)

# Make predictions on the test data
y_pred = rf_classifier.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

# Print classification report
print("Classification Report:")
print(classification_report(y_test, y_pred))

from sklearn.metrics import accuracy_score,roc_auc_score,roc_curve

sns.heatmap(confusion_matrix(y_test,y_pred), annot=True, fmt='d')

"""**Observation**


*   Random forest model gives us an overal accuracy score of 88.39%. It correctly predicts that 13721 studies were completed while 856 were terminated.
*  It also makes wrong prections that 431 studies were completed yet they were terminated and 1484 studies were terminated yet they were completed.

##**6.Conclusion**

*   There are various research approaches that are employed in clinical trials. The most commonly used according to the analysis is the interventional type of study.


*  The data reveals a predominant focus on adult and older adult participants, with limited representation of children and a gap in older adult involvement in clinical studies. Ensuring a more inclusive age distribution in research is crucial for comprehensive medical advancements.



*  In our exploration, we identified a select group of diseases that have garnered the most attention in clinical studies. These include Cancer related diseases,HIV/AIDS,Heart disease and COVID-19. This knowledge helps direct healthcare resources and research efforts to areas where they are most needed.


*   Our analysis highlighted the key sponsors who are driving clinical research.They include, National Cancer Institute, M.D Anderson Cancer Center,Memorial Sloan Kettering Cancer Center among others. Understanding these major stakeholders is crucial for assessing the funding and resource allocation in medical research.
*   Investigating the statuses of registered clinical studies, gave insights into the progress and success rates of ongoing research endeavors, which allows us to identify areas of potential improvement.



*   From the analysis, United States has emerged as a prominent hub for clinical studies.This geographic pattern reflects the presence of well-established research institutions, robust healthcare infrastructure, and patient populations conducive to clinical trials. While these hubs drive innovation, it also underscores the need for equitable distribution of research opportunities to ensure that medical advancements benefit a broader and more diverse population.
*   The data shows that many studies are done, which is good for progress. Some are still looking for participants, showing ongoing research. But there are also some we don't know much about, and some that got stopped. This tells us that clinical research can be uncertain, and it's important to find out why some studies don't go as planned to improve future trials.



* The predictive model we developed to forecast whether a clinical study is likely to be completed or terminated offers valuable insights into the factors influencing the outcome of these studies. By successfully utilizing this model, we gain a better understanding of the determinants that contribute to the successful completion of trials or their premature termination. This knowledge can guide stakeholders in making informed decisions and optimizing resources to increase the chances of successful clinical studies, ultimately advancing medical research and healthcare.

## 7.**Recomendation**

*   Given the prominence of cancer-related diseases, HIV/AIDS, heart disease, and COVID-19 in clinical studies, it is crucial to continue investing in research and allocating resources to these areas. Additionally, ensuring accessible and affordable healthcare for these conditions is essential for better health outcomes.
*   There is need for more collaboration with major sponsors in the clinical trials for impactful partnerships and funding hence successful clinical trials.


*   For areas with ongoing research, maintaining a system that monitors the progress and success rates of clinical studies is essential. Periodic reviews and quality assessments can help identify and address any issues, ensuring more efficient and successful trials.
*   While established research hubs are important, it's vital to promote a more balanced distribution of clinical studies to benefit a broader population. Encouraging research institutions in less prominent regions can help in achieving a more equitable spread of medical advancements.


* For studies with unknown or terminated statuses, there is a need for in-depth analysis to understand the reasons behind these outcomes. This analysis can guide future research efforts, ensuring a more efficient use of resources and better planning.  
*  Harness the power of predictive modelling as a pivotal tool in clinical trials. By integrating predictive modeling into the decision-making process, we can significantly enhance our ability to foresee study outcomes. This not only helps us avoid costly project stalls and untimely terminations but also enables us to allocate funds more effectively, maximizing the impact of our investments.
"""